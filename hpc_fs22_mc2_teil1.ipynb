{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6182aff8-cf1f-4b46-833c-4c04f16af751",
   "metadata": {},
   "source": [
    "# HPC Mini-Challenge 2 - Beschleunigung in Data Science\n",
    "#### FHNW - FS2022\n",
    "\n",
    "Original von S. Suter, angepasst für das HS22 von S. Marcin\n",
    "\n",
    "### Ressourcen\n",
    "* HPC mit Python – days 1-2 ([Videos](https://www.youtube.com/playlist?list=PL1tk5lGm7zvSC4rLm5Y71372R1Yxl2Dg_), [Github](https://github.com/eth-cscs/PythonHPC)), 2020:\n",
    "    - JupyterLab Tutorial (z.B. GPU Ressourcen)\n",
    "    - Introduction\n",
    "    - Vectorization\n",
    "    - Profiling\n",
    "    - JIT Numba CPU 1 + 2\n",
    "    - Siehe auch aktuelles Tutorial von 2021\n",
    "\n",
    "Abgabe von: <font color='blue'>Simon Luder</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c366e-061c-4ed1-b949-2e90e437962a",
   "metadata": {},
   "source": [
    "## Ausgangslage/Problemstellung\n",
    "\n",
    "\n",
    "Das menschliche Gehirn verliert mit zunehmendem Alter an Funktion. Ein Teil davon ist \"gesundes Altern\", d.h. es passiert bei jedem Menschen. Ein relativ großer Prozentsatz der alternden Bevölkerung erlebt jedoch auch einen kognitiven Rückgang, der extremer ist als bei anderen. Eine mildere Version davon wird als 'leichte kognitive Beeinträchtigung' (MCI) bezeichnet, bei der die Person grösstenteils noch funktionieren kann. Bei einem Teil der MCI-Patienten schreitet die Krankheit fort und führt zu Demenz bzw. Alzheimer. In diesem Projekt liegen uns MRI-Bilder des Gehirns von Alzheimerpatienten vor. Im spezifischen analysieren wir die Entwicklung von Alzheimer-Patienten anhand von MRI-Bildern, welche über eine bestimmte Zeit zur Verfügung stehen. Es stellt sich die Frage, wie gut sich die Veränderungen des Krankheitsbildes mittels Korrelationen über die Bildanalyse zeigen lassen. Zur Analyse sind Gigabytes von Daten in Form von 3D Gehirn-Scans vorhanden. Die Verarbeitung dieser grossen Datenmengen kann von Komprimierung profitieren.\n",
    "\n",
    "Das Verständnis von Gedächtnis- und Kognitionsstörungen und die Möglichkeit, den Gesundheitszustand des Gehirns zu erkennen, vorherzusagen und zu überwachen, ist ein gesellschaftlich und wirtschaftlich relevantes Thema der angewandten Wissenschaft. Alle neuen Erkenntnisse, die datenwissenschaftliche Methoden liefern können, werden zur Entwicklung von Lösungen beitragen, mit denen die Gesundheit des Gehirns erkannt, vorhergesagt und überwacht werden kann.\n",
    "\n",
    "### Daten\n",
    "[ADNI (Alzheimer's Disease Neuroimaging Initiative)](https://adni.loni.usc.edu/) ist ein internationales Projekt zur Erfassung von Daten über die Alzheimer-Krankheit und andere verwandte Gehirnerkrankungen, die zu einem kognitiven Abbau führen. Die Initiative wurde mit grossem Enthusiasmus aufgenommen, und viele Mitarbeiter aus der ganzen Welt haben Daten zur Verfügung gestellt, die sie in ihren eigenen Forschungsteams gesammelt haben. Die ADNI-Initiative ist ein öffentliches (gemeinnütziges) Projekt, da viele Forschungseinrichtungen auf der ganzen Welt mit Steuergeldern dazu beigetragen haben. Das bedeutet zwei Dinge: 1) Die Daten stehen uns für Forschungs- und Bildungszwecke zur Verfügung, 2) wir dürfen die Daten nicht an andere weitergeben oder kommerzialisieren.\n",
    "\n",
    "\n",
    "\n",
    "***Wichtig!*** Die Studierenden dürfen die Daten nur für Forschungszwecke verwenden und erhalten nur einen Beispielsdatensatz. Die ADNI-Daten dürfen nur lokal auf dem Computer oder auf FHNW-Ressourcen wie dem GitLab-Repository, d.h. nicht auf Github, gespeichert werden. Siehe [ADNI Datennutzungsvereinbarung](https://adni.loni.usc.edu/wp-content/uploads/how_to_apply/ADNI_Data_Use_Agreement.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c7a9d-4c2b-42e1-99d1-b52c06dd2148",
   "metadata": {},
   "source": [
    "<img src=\"images/mri-example.png\" alt=\"MRI example image (coronal slice)\" width=\"150\"/> <img src=\"images/slicing.png\" alt=\"Slicing\" width=\"400\"/>\n",
    "\n",
    "Links: MRI Beispielbild (coronaler Schnitt), rechts: MRI slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd1819-dd4d-45dc-9e0b-ac9944a52bdd",
   "metadata": {},
   "source": [
    "## Zielsetzung\n",
    "\n",
    "In dieser Aufgabe sollen die Parallelisierung und Beschleunigung unterschiedlicher Methoden von Bildrekonstruktion basierend auf komprimierten (zerlegten) Daten implementiert, analyisiert und diskutiert werden. Die Rekonstruktion der Daten aus der komprimierten Version soll dabei möglichst in Echtzeit geschehen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b20755-6990-41a7-b745-a7f15f906c93",
   "metadata": {},
   "source": [
    "## Lösungsweg / Vorgehen\n",
    "\n",
    "Wir lösen diese Aufgabenstellung indem wir die Singulärwertzerlegung (SVD: singular value decomposition) als Kompressionsmethode verwenden (Matrixfaktorisierung). Siehe Abbildungen unten. Um die Rekonstruktion der Daten aus der SVD-Matrixfaktoriseriung möglichst in Echtzeit zu bewerkstelligen, evaluieren wir dafür verschiedene Methoden der Parallelisierung und Beschleunigung in Python. \n",
    "* Beschleunigungsvarianten auf der CPU:\n",
    "    - Numpy Operationen inkl. Broadcasting\n",
    "    - Numba\n",
    "    - Threads\n",
    "* Beschleunigung auf der GPU:\n",
    "    - Cupy (analog zu Numpy)\n",
    "    - Numba (analog zu Numba)\n",
    "\n",
    "<img src=\"images/svd_reco.png\" alt=\"svd vis\" width=\"500\"/> <img src=\"images/svd.png\" alt=\"svd\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341c0dc-9b76-4f2e-97e8-4e0af427651b",
   "metadata": {},
   "source": [
    "## Daten Zerlegen\n",
    "### 1.1 Daten laden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8809d-0ce0-48de-8c61-f7476ca93ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "subfolder = '001'\n",
    "folders = os.path.join('adni_png', subfolder)\n",
    "n = 3\n",
    "\n",
    "\n",
    "images = np.empty([n,256,170])\n",
    "idx = 0\n",
    "names = []\n",
    "for filename in os.listdir(folders):\n",
    "    if filename.endswith('.png') and '145' in filename:\n",
    "        with open(os.path.join(folders, filename), 'r') as f:\n",
    "            im = imageio.imread(f.name)\n",
    "            names.insert(idx,f.name[-17:-4])\n",
    "            images[idx,:,:] = im\n",
    "            print (names[idx], im.shape)\n",
    "            idx += 1\n",
    "            if idx >=n:\n",
    "                break\n",
    "            \n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791339c9-e447-482f-87d2-3552c84c58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "for a in range(images.shape[0]):\n",
    "    ax = fig.add_subplot(1,images.shape[0],a+1)\n",
    "    ax.imshow(images[a],cmap='gray')\n",
    "    ax.set_title(names[a])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32592680-75d0-4246-87f5-bea68369af73",
   "metadata": {},
   "source": [
    "### 1.2 Daten zerlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1500d6-0027-404b-a7b0-c4101dbbefab",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = images[0]\n",
    "im = im -im.min() / im.max() - im.min() # normalize data \n",
    "u,s,vt = np.linalg.svd(im, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5552bf-f3e9-474a-922c-532054f623a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_svd(u,s,vt,k):\n",
    "    \"\"\"SVD reconstruction for k components using np.dot()\n",
    "    \n",
    "    Inputs:\n",
    "    u: (m,n) numpy array\n",
    "    s: (n) numpy array (diagonal matrix)\n",
    "    vt: (n,n) numpy array\n",
    "    k: number of reconstructed singular components\n",
    "    \n",
    "    Ouput:\n",
    "    (m,n) numpy array U_mk * S_k * V^T_nk for k reconstructed components\n",
    "    \"\"\"\n",
    "    reco = np.dot(u[...,:k], np.dot(np.diag(s[:k]), vt[:k,...]))\n",
    "        \n",
    "    return reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d3a5c-fbe1-41e8-b7e7-0af890d1abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import metrics\n",
    "\n",
    "# calculate various metrics for the reconstruction quality\n",
    "def calculate_metrics(im, reco):\n",
    "    mse = metrics.mean_squared_error(im, reco)\n",
    "    ssim_score = metrics.structural_similarity(im, reco)\n",
    "    hdist = metrics.hausdorff_distance(im, reco)\n",
    "    return f\"MSE: {mse:.2f}, SSIM {ssim_score:.2f}, HDIST: {hdist:.2f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb294e89-79b3-45b3-8758-11d041100555",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(images.shape[0], 6, figsize=(30,20))\n",
    "\n",
    "for a in range(images.shape[0]):\n",
    "    im = images[a]\n",
    "    im = im -im.min() / im.max() - im.min()    \n",
    "    u,s,vt = np.linalg.svd(im, full_matrices=False)\n",
    "\n",
    "    axs[a, 0].imshow(im,cmap='gray')\n",
    "    axs[a, 0].set_title(names[a])\n",
    "    \n",
    "    if (a == 0):\n",
    "        print('original size: ', im.shape[0]*im.shape[1])\n",
    "    \n",
    "    for idx, n in enumerate(range(s.shape[0], 0, -40)):\n",
    "        reco = reconstruct_svd(u,s,vt,n)\n",
    "        if (a == 0):\n",
    "            print('decomposed to n = ', n , ', size: ', u.shape[0] * n + n + vt.shape[0]*n)\n",
    "    \n",
    "        axs[a, idx+1].imshow(reco,cmap='gray')\n",
    "        axs[a, idx+1].set_title('reco n=' + str(n) + ', ' + calculate_metrics(im, reco))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400e1a8-8279-4a35-8fbc-2010a5ac9d8e",
   "metadata": {},
   "source": [
    "### 2 Rekonstruktionsvarianten\n",
    "Siehe Bilder in der Einführung (Teil: Vorgehen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679d0b3-6a51-4a31-8c9d-6bb66bc40b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to visualze reconstruction\n",
    "def plot_reco(reco, k):\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.imshow(reco,cmap='gray')\n",
    "    ax.set_title('reco with ' + str(k)+ ' components')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d3a28-034d-4b93-a1e5-ed7603354830",
   "metadata": {},
   "source": [
    "#### 2.1 For-Loops\n",
    "Rekonstruiere nun die zerlegte SVD Matrix mittels For-Loops gemäss Formel B.4 (oben). Rekonstruiere nur die ersten $k$ Komponenten der SVD-Matrixfaktorisierung $U, S, V^T$, wobei $U \\in \\mathbb{R}^{MxN}$, $S \\in \\mathbb{R}^{N}$, und  $V^T \\in \\mathbb{R}^{NxN}$. \n",
    "\n",
    "Implementiere dafür folgende drei Funktionen - jeweils mit 3, 2 bzw. 1 For-Loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a5359-b849-4cba-a0c4-1e7ab3837e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_svd_for_loops3(u,s,vt,k):\n",
    "    \"\"\"SVD reconstruction for k components using 3 for-loops\n",
    "    \n",
    "    Inputs:\n",
    "    u: (m,n) numpy array\n",
    "    s: (n) numpy array (diagonal matrix)\n",
    "    vt: (n,n) numpy array\n",
    "    k: number of reconstructed singular components\n",
    "    \n",
    "    Ouput:\n",
    "    (m,n) numpy array U_mk * S_k * V^T_nk for k reconstructed components\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    reco = np.zeros((u.shape[0], vt.shape[1]))\n",
    "        \n",
    "    for i in range(u.shape[0]):\n",
    "        for j in range(vt.shape[1]):\n",
    "            for n in range(k):\n",
    "                reco[i][j] += np.dot(u[i][n], np.dot(s[n], vt[n][j]))\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39738322-2bb9-4014-9daf-5815cf9b0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_svd_for_loops2(u,s,vt,k):\n",
    "    \"\"\"SVD reconstruction for k components using 2 for-loops\n",
    "    \n",
    "    Inputs:\n",
    "    u: (m,n) numpy array\n",
    "    s: (n) numpy array (diagonal matrix)\n",
    "    vt: (n,n) numpy array\n",
    "    k: number of reconstructed singular components\n",
    "    \n",
    "    Ouput:\n",
    "    (m,n) numpy array U_mk * S_k * V^T_nk for k reconstructed components\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    reco = np.zeros((u.shape[0], vt.shape[1]))\n",
    "        \n",
    "    for i in range(u.shape[0]):\n",
    "        for j in range(vt.shape[1]):\n",
    "            reco[i,j] += np.dot(u[i,:k], np.dot(np.diag(s[:k]), vt[:k, j]))\n",
    "     \n",
    "    ### END SOLUTION\n",
    "\n",
    "    return reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2443a152-eff7-43da-855b-682da49a6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_svd_for_loops1(u,s,vt,k):\n",
    "    \"\"\"SVD reconstruction for k components using 1 for-loop and np.outer()\n",
    "    \n",
    "    Inputs:\n",
    "    u: (m,n) numpy array\n",
    "    s: (n) numpy array (diagonal matrix)\n",
    "    vt: (n,n) numpy array\n",
    "    k: number of reconstructed singular components\n",
    "    \n",
    "    Ouput:\n",
    "    (m,n) numpy array U_mk * S_k * V^T_nk for k reconstructed components\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    reco = np.zeros((u.shape[0], vt.shape[1]))\n",
    "    \n",
    "    for n in range(k):\n",
    "        reco += np.outer(u[...,n], np.outer(s[n], vt[n,...]))\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return reco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a153e3-9d52-40da-ab36-24c88a14f0c0",
   "metadata": {},
   "source": [
    "#### 2.2 Einstein Summation\n",
    "Implementiere nun eine möglichst schnelle Rekonstruktionsvariante mittels `np.einsum()` gemäss folgender Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b445e-ba25-4151-907f-ea3b43c3e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_svd_einsum1(u,s,vt,k):\n",
    "    \"\"\"SVD reconstruction for k components using broadcast\n",
    "    \n",
    "    Inputs:\n",
    "    u: (m,n) numpy array\n",
    "    s: (n) numpy array (diagonal matrix)\n",
    "    vt: (n,n) numpy array\n",
    "    k: number of reconstructed singular components\n",
    "    \n",
    "    Ouput:\n",
    "    (m,n) numpy array U_mk * S_k * V^T_nk for k reconstructed components\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    reco = np.einsum(\"ij,jh->ih\", u[...,:k], np.einsum(\"ij,jh->ih\", np.diag(s[:k]), vt[:k,...]))\n",
    "\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return reco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ff53c-b8e0-4b15-8441-a4bf5a0d8ade",
   "metadata": {},
   "source": [
    "#### 2.3 Broadcasting\n",
    "Implementiere nun zwei Rekonstruktionsvarianten mittels Broadcasting.\n",
    "\n",
    "Links:\n",
    "- https://machinelearningmastery.com/broadcasting-with-numpy-arrays/\n",
    "- https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
    "- https://eli.thegreenplace.net/2015/broadcasting-arrays-in-numpy/\n",
    "- https://scipy.github.io/old-wiki/pages/EricsBroadcastingDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f945e061-baf7-47bc-bd3d-8cf59f6709f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_svd_broadcast1(u,s,vt,k):\n",
    "    \"\"\"SVD reconstruction for k components using broadcast variant 1\n",
    "    \n",
    "    Inputs:\n",
    "    u: (m,n) numpy array\n",
    "    s: (n) numpy array (diagonal matrix)\n",
    "    vt: (n,n) numpy array\n",
    "    k: number of reconstructed singular components\n",
    "    \n",
    "    Ouput:\n",
    "    (m,n) numpy array U_mk * S_k * V^T_nk for k reconstructed components\n",
    "    \"\"\"\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    reco = np.zeros((u.shape[0], vt.shape[1]))\n",
    "    \n",
    "    for n in range(k):\n",
    "        reco += (u[...,n].reshape(-1, 1) * s[n] * vt[n,...])\n",
    "            \n",
    "    ### END SOLUTION\n",
    "\n",
    "    return reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fa6aa-07e7-4375-a0cc-95d0b2875da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_svd_broadcast2(u,s,vt,k):\n",
    "    \"\"\"SVD reconstruction for k components using broadcast variant 2\n",
    "    \n",
    "    Inputs:\n",
    "    u: (m,n) numpy array\n",
    "    s: (n) numpy array (diagonal matrix)\n",
    "    vt: (n,n) numpy array\n",
    "    k: number of reconstructed singular components\n",
    "    \n",
    "    Ouput:\n",
    "    (m,n) numpy array U_mk * S_k * V^T_nk for k reconstructed components\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    reco = np.zeros((u.shape[0], vt.shape[1]))\n",
    "\n",
    "    for i in range(u.shape[0]):\n",
    "        for j in range(vt.shape[1]):\n",
    "            reco[i][j] = sum(s[:k] * u[i,:k] * vt[:k, j])\n",
    "\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return reco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c24543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "u,s,vt = np.linalg.svd(im, full_matrices=False)\n",
    "reco = reconstruct_svd_for_loops1(u,s,vt,k=170)\n",
    "plt.imshow(reco, cmap='gray')\n",
    "calculate_metrics(im, reco)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459ff399-c608-40b3-b59c-ba66012418f5",
   "metadata": {},
   "source": [
    "#### 2.4 Vergleich der Resultate\n",
    "Vergleiche die Resultate der Implementierungen anhand eines Beispielbildes. Sind die Rekonstruktionen nahezu gleich? Wie sieht es mit der Rekonstruktionsgeschwindigkeit aus - abhängig von der Anzahl rekonstruierter Komponenten?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7359f45",
   "metadata": {},
   "source": [
    "<font color='blue'>Nachfolgend wird die Bildrekonstruktion für ein einzelnes Bild mit k=170 ausgeführt. Unter der Verwendung aller Singulärwerte ist zu erwarten, dass alle Methoden bei korrekter Implementierung eine perfekte Rekonstruktion des ursprünglichen Bildes erreichen. Die Rekonstruktion wird mittels den Metriken *mean squared error (MSE)*, *structural similarity (SSIM)* und *hausdorff_distance (HDIST)* verglichen.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import math\n",
    "im = images[0]\n",
    "u,s,vt = np.linalg.svd(im, full_matrices=False)\n",
    "k=170\n",
    "\n",
    "methods = [reconstruct_svd, \n",
    "           reconstruct_svd_for_loops1, \n",
    "           reconstruct_svd_for_loops2, \n",
    "           reconstruct_svd_for_loops3, \n",
    "           reconstruct_svd_einsum1, \n",
    "           reconstruct_svd_broadcast1, \n",
    "           reconstruct_svd_broadcast2\n",
    "          ]\n",
    "\n",
    "reconstructions = dict()\n",
    "for method in methods:\n",
    "    print(f\"Running reconnstruction with: {method.__name__}\")\n",
    "    reconstructions[method.__name__] = method(u,s,vt,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "fig, axs = plt.subplots(math.ceil(len(methods)/n), n, figsize=(18,18))\n",
    "\n",
    "for i, r in enumerate(reconstructions):\n",
    "    axs[i//n, i%n].imshow(reconstructions[r],cmap='gray')\n",
    "    axs[i//n, i%n].set_title(f\"method={r}\\nreco n= {k}\\n{calculate_metrics(im, reconstructions[r])}\")\n",
    "    \n",
    "for i in range(math.ceil(len(methods)/n)*n):\n",
    "    axs[i//n, i%n].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4ab0e",
   "metadata": {},
   "source": [
    "<font color='blue'>Wir sehen, dass alle Bilder dieselben Werte für die Vergleichsmetriken in der Rekonstruktion erreicht haben. Ein *MSE* von 0 bedeutet, als auch der *SSIM* von 1 bedeutet, dass es keine Abweichungen zwischen der Rekonstruktion und dem Original gibt.</font>\n",
    "\n",
    "\n",
    "<font color='blue'>In einem nächsten Schritt werden nun noch die Laufzeiten der unterschiedlichen Implementierungen verglichen.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102c059-3e7c-4587-94e2-0081fcd65d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import timeit\n",
    "\n",
    "class TimeLogger():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__logger = []\n",
    "\n",
    "    def log_time(self, method, k_range, repeat, number):\n",
    "        print(f\"running with: {method.__name__}\")\n",
    "        \n",
    "        for k in k_range:\n",
    "            t = timeit.Timer(lambda: method( u, s, vt, k))\n",
    "            time = t.repeat(repeat=repeat, number=number)\n",
    "\n",
    "            mean, std = np.mean(time), np.std(time)\n",
    "            \n",
    "            log = dict()\n",
    "            log[\"name\"] = method.__name__\n",
    "            log[\"k\"] = k\n",
    "            log[\"repeat\"] = repeat\n",
    "            log[\"number\"] = number\n",
    "            log[\"mean\"] = mean\n",
    "            log[\"std\"] = std\n",
    "                \n",
    "            self.__logger.append(log)\n",
    "                \n",
    "    def get_log(self):\n",
    "        return self.__logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db31863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k_range = range(im.shape[1], 10, -40)\n",
    "\n",
    "logger = TimeLogger()\n",
    "\n",
    "logger.log_time(method=reconstruct_svd, k_range=k_range, repeat=50, number=100)\n",
    "\n",
    "logger.log_time(method=reconstruct_svd_for_loops1, k_range=k_range, repeat=20, number=10)\n",
    "\n",
    "logger.log_time(method=reconstruct_svd_for_loops2, k_range=k_range, repeat=3, number=3)\n",
    "\n",
    "logger.log_time(method=reconstruct_svd_for_loops3, k_range=k_range, repeat=1, number=1)\n",
    "\n",
    "logger.log_time(method=reconstruct_svd_einsum1, k_range=k_range, repeat=50, number=50)\n",
    "\n",
    "logger.log_time(method=reconstruct_svd_broadcast1, k_range=k_range, repeat=20, number=10)\n",
    "\n",
    "logger.log_time(method=reconstruct_svd_broadcast2, k_range=k_range, repeat=5, number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372bdf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "log = logger.get_log()\n",
    "df = pd.DataFrame.from_records(log)\n",
    "df[\"mean_per_number\"] = df[\"mean\"] / df[\"number\"]\n",
    "df[df[\"k\"]==170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aaf83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "# sns.lineplot(data=df, x=\"k\", y=\"mean_per_number\", hue=\"name\")\n",
    "# sns.scatterplot(data=df, x=\"k\", y=\"mean_per_number\", hue=\"name\")\n",
    "sns.barplot(data=df, x=\"k\", y=\"mean_per_number\", hue=\"name\").set_yscale(\"log\")\n",
    "plt.title(\"Time needed for reconstruction\")\n",
    "plt.xlabel(\"singular values [k]\")\n",
    "plt.ylabel(\"time per function call [s]\")\n",
    "plt.show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fdde9-004c-400a-8caa-ce950cf8ba7e",
   "metadata": {},
   "source": [
    "#### 2.5 Interpretation der Resultate\n",
    "\n",
    "Welche der Implementierungen war am schnellsten? Was waren deine Beobachtungen während  der Implementierung? Wo können solche Optimierungen sonst noch eingesetzt werden? Diskutiere in ca. 150-200 Wörtern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c9fac-ca2b-44e5-903c-639132e3e90a",
   "metadata": {},
   "source": [
    "<font color='blue'>Von allen untersuchten Methoden ist die Rekonstruktion mit `np.dot` mit Abstand am schnellsten und benötigt weniger als 1 ms für die Rekonstruktion bei k=170. Das liegt daran, dass die numpy Library im Hintergrund auf kompiliertem C-Code läuft.</font>\n",
    "\n",
    "<font color='blue'>Alle Varianten, welche mit for-loops implementiert wurden sind wie zu erwarten deutlich langsamer. So wird bei k=170 für reconstruct_svd_for_loops1 ca. 10 ms, reconstruct_svd_for_loops1 ca. 1300 ms und reconstruct_svd_for_loops1 ca. 32000 ms benötigt.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704aa64e-ccf0-4c72-9ee8-61b58df6308e",
   "metadata": {},
   "source": [
    "### 3 Parallelisierung mittels Numba\n",
    "\n",
    "Implementiere nun eine möglichst schnelle Rekonstruktionsvariante des SVDs mittels Numba. Ist es möglich, den Code mit Numba zu beschleunigen? Führe dazu eine Diagnostik aus. Wenn ja, was ist der Speedup-Faktor und welche(r) Teil(e) konnte(n) parallelisiert werden? Falls nein, was sind die Gründe, weshalb es sich nicht parallelisieren lässt? Lassen sich verschachtelte Schleifen parallelisieren? Warum? Diskutiere in ca. 150-200 Wörtern, wann und warum sich Numba für die Parallelisierung eignet - anhand deines Beispiels.\n",
    "\n",
    "Beachte:\n",
    "* Beim ersten Mal Ausführen des Codes wird die Zeit des Kompilierens mit eingerechnet.\n",
    "* Numba eignet sich gut für For-Schleifen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d60a7-c9f8-43b9-afab-2480a12a561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "from numba import jit\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "### END SOLUTION\n",
    "@jit(nopython=True)\n",
    "def reconstruct_svd_numba(u,s,vt,k):\n",
    "    \"\"\"SVD reconstruction for k components using numba\n",
    "    \n",
    "    Inputs:\n",
    "    u: (m,n) numpy array\n",
    "    s: (n) numpy array (diagonal matrix)\n",
    "    vt: (n,n) numpy array\n",
    "    k: number of reconstructed singular components\n",
    "    \n",
    "    Ouput:\n",
    "    (m,n) numpy array U_mk * S_k * V^T_nk for k reconstructed components\n",
    "    \"\"\"\n",
    "### BEGIN SOLUTION\n",
    "    reco = np.dot(u[...,:k], np.dot(np.diag(s[:k]), vt[:k,...]))\n",
    "### END SOLUTION\n",
    "\n",
    "    return reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d636e97b-01f7-414c-ad12-92dbf633082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "im = images[0]\n",
    "u,s,vt = np.linalg.svd(im, full_matrices=False)\n",
    "\n",
    "test = reconstruct_svd_numba(u,s,vt,k=10)\n",
    "plt.imshow(test, cmap='gray')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac641631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.log_time(method=reconstruct_svd_numba, k_range=k_range, repeat=50, number=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403be7ac-3a69-45f3-80bf-10249c244220",
   "metadata": {},
   "source": [
    "<font color='blue'>Antwort hier eingeben</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4814d06-af72-43ce-9aca-522e8ec52fe3",
   "metadata": {},
   "source": [
    "### 4 Parallelisierung mit Threads\n",
    "\n",
    "Als nächstes Parallelisieren wir die Rekonstruktion der SVD zerlegten Matrizen mittels unterschiedlichen Thread-Varianten.\n",
    "\n",
    "Links:\n",
    "* Threading in Python ([Videokurs](https://realpython.com/courses/threading-python/), [Blogartikel](https://realpython.com/intro-to-python-threading/), [Quiz](https://realpython.com/quizzes/python-threading/)), RealPython\n",
    "* https://github.com/eth-cscs/PythonHPC/tree/master/intro\n",
    "* Slides vom Kurs kvanc zum Thema IPC mittels Python\n",
    "\n",
    "#### 4.1 Einzelne Threads auf einer CPU\n",
    "\n",
    "Implementiere eine Funktion, welche ein Rekonstruktionsschritt in Thread rekonstruiert. Wähle selbst welchen Schritt du mittels Threading implementierst. Verwende dabei geeignete Lock-Mechanismen. Verwende vor und nach den Lock-Mechanismen geeignete Print/Log-Statements und verwende unterschiedliche Farben der Print-Statements für die Threads. Validiere dein Ergebnis der Rekonstruktion indem du mehrere Threads für einzelne Rekonstruktionsschritte aufruftst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb48aad-826e-416f-abc3-132f7a2152c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import threading\n",
    "\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "\n",
    "\n",
    "\n",
    "class ReconstructSVDThreading():\n",
    "    \n",
    "    def __init__(self, hsplit, wsplit):\n",
    "        self.colors = ['\\033[91m', '\\033[92m', '\\033[93m', '\\033[94m', '\\033[95m', '\\033[96m', '\\033[97m', '\\033[98m']\n",
    "        self.lock = threading.Lock()\n",
    "        self.hsplit = hsplit\n",
    "        self.wsplit = wsplit\n",
    "        \n",
    "    def get_args(self):\n",
    "        \n",
    "        args = []\n",
    "        u_ = np.array_split(self.u, self.hsplit, axis=0)\n",
    "        vt_ = np.array_split(self.vt.T, self.wsplit, axis=1)\n",
    "        \n",
    "        u_from, u_to,  = 0, 0\n",
    "        for h in range(self.hsplit):\n",
    "            u_to += u_[h].shape[0]\n",
    "            \n",
    "            vt_from, vt_to = 0, 0\n",
    "            for w in range(self.wsplit):\n",
    "                vt_to += vt_[w].shape[1]\n",
    "                \n",
    "                args.append([(u_from, u_to), (vt_from, vt_to), k, h*self.wsplit+w])\n",
    "                \n",
    "                vt_from += vt_[w].shape[1]\n",
    "            u_from += u_[h].shape[0]\n",
    "        return args\n",
    "\n",
    "    \n",
    "    def start_threads(self, u,s,vt,k):\n",
    "    \n",
    "        \n",
    "        self.reco = np.zeros((u.shape[0], vt.shape[1]))\n",
    "        self.u, self.s, self.vt, self.k = u, s, vt, k\n",
    "\n",
    "        threads = []\n",
    "        args = self.get_args()\n",
    "        \n",
    "        for i in range(self.hsplit * self.wsplit):\n",
    "            t = threading.Thread(target=self.reconstruct_svd_for_loops2, args=args[i])\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "    \n",
    "    def reconstruct_svd_for_loops2(self, u_idx, vt_idx, k, c):\n",
    "        for i in range(u_idx[0],u_idx[1]):\n",
    "            for j in range(vt_idx[0],vt_idx[1]):\n",
    "                self.reco[i,j] += np.dot(self.u[i,:k].reshape(1,-1), np.dot(np.diag(self.s)[:k, :k], self.vt[:k, j].reshape(-1,1)))\n",
    "                print(f\"{self.colors[c]}Reconsturct: im[{i}][{j}]\")\n",
    "  \n",
    "        \n",
    "    def get_reconstruction(self):\n",
    "        return self.reco\n",
    "\n",
    "    \n",
    "    \n",
    "k=60\n",
    "reconstructor = ReconstructSVDThreading(hsplit=2, wsplit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c23fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time reconstructor.start_threads(u,s,vt,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e4563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,10))\n",
    "plt.imshow(reconstructor.get_reconstruction(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af779ae2",
   "metadata": {},
   "source": [
    "In Python wird der Code standardmässig über ein Global Interpreter Lock [GIL](https://realpython.com/python-gil/) ausgeführt. Dieses Stellt sicher, dass jeweils nur ein Thread in Python zugriff auf den Python Interpreter erhält und ausgeführt wird.\n",
    "\n",
    "Mit der Threading Library ist es möglich Mehrere Threads in Python zu deklarieren. Diese greifen wärend der Laufzeit abwechslungsweise auf das GIL zu, was eine Konkurente Ausführung der Threads führt.\n",
    "\n",
    "Lock.quire / Lock.release\n",
    "Greifen mehrere Threads auf dieselbe Ressource konkurrent zu und modifizieren diese, kann das zu Problemen in der Konsistenz der Daten führen. Gibt es Schritte im Code, welche aufeinanderfolgend ausgeführt werden müssen, kann einem bestimmten Thread mittels `threading.Lock`, resp. `Lock.aquire` ein ungeteilter Zugriff auf das GIL garantiert werden. Wird das GIL nicht mehr Benötigt, muss es anschliessend mittels `Lock.release` wieder für die anderen Threads freigegeben werden.\n",
    "In meinem Falle sehe ich keine notewendinge Anwendung von Locks, da ich keine Synchrone bearbeitung derselben Daten benötige."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b84a95-f136-4f1f-99e1-408cf838eec9",
   "metadata": {},
   "source": [
    "#### 4.2 Bonus: Thread-Pool-Executor\n",
    "\n",
    "Rufe zum Vergleich die unabhängige Rekonstruktionsschritte mittels eines Thread-Pool-Executors auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import concurrent\n",
    "# import time\n",
    "# from multiprocessing import shared_memory\n",
    "# import numpy as np\n",
    "# import multiprocessing\n",
    "# from concurrent.futures.process import ProcessPoolExecutor\n",
    "\n",
    "# NUM_WORKERS = multiprocessing.cpu_count()\n",
    "# np.random.seed(42)\n",
    "# ARRAY_SIZE = int(2e8)\n",
    "# ARRAY_SHAPE = (ARRAY_SIZE,)\n",
    "# NP_SHARED_NAME = 'npshared'\n",
    "# NP_DATA_TYPE = np.float\n",
    "# data = np.random.random(ARRAY_SIZE).astype(np.int)\n",
    "\n",
    "\n",
    "# def create_shared_memory_nparray(data):\n",
    "#     d_size = np.dtype(NP_DATA_TYPE).itemsize * np.prod(ARRAY_SHAPE)\n",
    "    \n",
    "\n",
    "#     shm = shared_memory.SharedMemory(create=True, size=d_size, name=NP_SHARED_NAME)\n",
    "#     # numpy array on shared memory buffer\n",
    "#     dst = np.ndarray(shape=ARRAY_SHAPE, dtype=NP_DATA_TYPE, buffer=shm.buf)\n",
    "#     dst[:] = data[:]\n",
    "#     print(f'NP SIZE: {(dst.nbytes / 1024) / 1024}')\n",
    "#     return shm\n",
    "\n",
    "\n",
    "# def release_shared(name):\n",
    "#     shm = shared_memory.SharedMemory(name=name)\n",
    "#     shm.close()\n",
    "#     shm.unlink()  # Free and release the shared memory block\n",
    "\n",
    "    \n",
    "# def np_sum(name, start, stop):\n",
    "#     # not mandatory to init it here, just for demostration purposes.\n",
    "#     shm = shared_memory.SharedMemory(name=name)\n",
    "#     np_array = np.ndarray(ARRAY_SHAPE, dtype=NP_DATA_TYPE, buffer=shm.buf)\n",
    "#     return np.sum(np_array[start:stop])\n",
    "\n",
    "  \n",
    "# def benchmark():\n",
    "#     chunk_size = int(ARRAY_SIZE / NUM_WORKERS)\n",
    "#     futures = []\n",
    "#     ts = time.time_ns()\n",
    "#     with ProcessPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "#         for i in range(0, NUM_WORKERS):\n",
    "#             start = i + chunk_size if i == 0 else 0\n",
    "#             futures.append(executor.submit(np_sum, NP_SHARED_NAME, start, i + chunk_size))\n",
    "#     futures, _ = concurrent.futures.wait(futures)\n",
    "#     return (time.time_ns() - start_time) / 1_000_000\n",
    "\n",
    "  \n",
    "# if __name__ == '__main__':\n",
    "#     shm = create_shared_memory_nparray(data)\n",
    "#     benchmark2()\n",
    "#     release_shared(NP_SHARED_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a9f288",
   "metadata": {},
   "source": [
    "#### 4.3 Bonus: Threads auf mehreren CPUs\n",
    "\n",
    "Verwende anstelle von Threading Multiprocessing damit die Threads auf mehrere CPUs verteilt werden.\n",
    "\n",
    "Links:\n",
    "* Concurrency [Blog](https://realpython.com/python-concurrency/), [Quiz](https://realpython.com/quizzes/python-concurrency/), RealPython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3cdc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing_class import ReconstructSVDMultiprocessing\n",
    "\n",
    "\n",
    "k=60\n",
    "u,s,vt = np.linalg.svd(im, full_matrices=False)\n",
    "reconstructor = ReconstructSVDMultiprocessing(hsplit=2, wsplit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a3527",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time reconstructor.start_processes(u,s,vt,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec149ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,10))\n",
    "plt.imshow(reconstructor.get_reconstruction(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ff161a-4f0b-458a-af75-eb1616325536",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 4.4 Analyse\n",
    "\n",
    "1. Macht es in diesem Beispiel Sinn Threads zu benutzen? Wann ist es sinnvoll Threads zu benutzen? Beschreibe in 2-3 Sätzen warum. \n",
    "\n",
    "<font color='blue'>In diesem Beispiel macht es meiner Meinung nach keinen Sinn, Threads einzusetzen. Einerseits ist der Rechenaufwand pro Bild nicht ausreichen, dass es sich lohnt die Matrizzenrekonstruktion (sofern halbwegs intelligent implementiert) zu parallelisieren. Andererseits ist der wesentliche Zeitaufwand dem Ausrechnen auf der PCU geschuldet, wo durch konkurrente Ausführung keine Zeiteinsparrung erreicht werden kann. </font>\n",
    "\n",
    "2. Könnten in diesem Beispiel auch andere Code-Teile auf mehreren Threads aufgerufen werden? Welche würden sich eignen? Welche nicht? Beschreibe in 2-3 Sätzen warum. \n",
    "\n",
    "<font color='blue'>Antwort hier eingeben</font>\n",
    "\n",
    "3. Was sind die Unterschiede (auch bzgl. Leistung) der manuellen Ausführung des Threadings vs. dem Benutzen eines Thread-Pool-Executors oder von Multiprocessing?\n",
    "\n",
    "<font color='blue'>\n",
    "    Beim Multiprocessing wird die Arbeit effektiv auf mehrere CPU Kerne verteilt.\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2e916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
